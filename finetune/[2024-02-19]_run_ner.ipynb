{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# import numpy as np\n",
    "import torch\n",
    "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "# from torch.nn import CrossEntropyLoss\n",
    "# from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from attrdict import AttrDict\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from huggingface_hub import notebook_login, create_repo, delete_repo, Repository, upload_file, delete_file\n",
    "\n",
    "# from transformers import (\n",
    "#     AdamW,\n",
    "#     get_linear_schedule_with_warmup\n",
    "# )\n",
    "\n",
    "from src import (\n",
    "    CONFIG_CLASSES,\n",
    "    TOKENIZER_CLASSES,\n",
    "    MODEL_FOR_TOKEN_CLASSIFICATION,\n",
    "    init_logger,\n",
    "    set_seed,\n",
    "    # compute_metrics,\n",
    "    # show_ner_report\n",
    ")\n",
    "\n",
    "from processor import ner_load_and_cache_examples as load_and_cache_examples\n",
    "from processor import ner_tasks_num_labels as tasks_num_labels\n",
    "from processor import ner_processors as processors\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from run_ner import train_v2, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39fb26efaa04aec98c8527135e9c843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 로그인\n",
    "# 토큰링크: https://huggingface.co/settings/tokens\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 내 레포지토리 로드\n",
    "\n",
    "# REPO_NAME = \"cujabes/koelectra-small-v3-discriminator\"\n",
    "# repo = Repository(local_dir=, clone_from=REPO_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/19/2024 08:05:33 - INFO - __main__ -   Training/evaluation parameters AttrDict({'task': 'naver-ner', 'data_dir': '../../../../data/KoELECTRA', 'ckpt_dir': 'ckpt', 'train_file': 'train.tsv', 'dev_file': '', 'test_file': 'test.tsv', 'evaluate_test_during_training': True, 'eval_all_checkpoints': True, 'save_optimizer': False, 'do_lower_case': False, 'do_train': True, 'do_eval': True, 'max_seq_len': 128, 'num_train_epochs': 30, 'weight_decay': 0.0, 'gradient_accumulation_steps': 1, 'adam_epsilon': 1e-08, 'warmup_proportion': 0, 'max_steps': -1, 'max_grad_norm': 1.0, 'no_cuda': False, 'model_type': 'koelectra-small-v3', 'model_name_or_path': 'cujabes/koelectra-small-v3-discriminator', 'output_dir': '../../../../models/KoELECTRA', 'seed': 42, 'train_batch_size': 32, 'eval_batch_size': 128, 'logging_steps': 1000, 'save_steps': 1000, 'learning_rate': 5e-05, 'vocab_size': 80000, 'limit_alphabet': 6000, 'un_used_num': 10000})\n"
     ]
    }
   ],
   "source": [
    "config_path = \"../../../../data/KoELECTRA_config/naver-ner/koelectra-small-v3.json\"\n",
    "# Read from config file and make args\n",
    "with open(config_path) as f:\n",
    "    args = AttrDict(json.load(f))\n",
    "logger.info(\"Training/evaluation parameters {}\".format(args))\n",
    "\n",
    "# args.output_dir = os.path.join(args.ckpt_dir, args.output_dir)\n",
    "\n",
    "init_logger()\n",
    "set_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WP 토크나이저 생성중\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "vocab 파일 이동 ../../../../models/KoELECTRA/repo/vocab.txt -> ../../../../models/KoELECTRA/vocab/vocab_80000_6000_20240219.txt\n",
      "new vocab 파일 저장 ../../../../models/KoELECTRA/repo/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "### tokenizer 학습\n",
    "\n",
    "vocab_path = \"../../../../models/KoELECTRA/repo/vocab.txt\"\n",
    "train_file_path = os.path.join(args.data_dir, args.task, args.train_file)\n",
    "output_dir = os.path.join(args.output_dir, \"%s-%s\"%(args.model_type, args.task), \"checkpoint-best\")\n",
    "# model_path = os.path.join(output_dir, \"vocab.txt\")\n",
    "move_vocab_path = os.path.join(args.output_dir, \"vocab\", \"old_vocab_20240219.txt\")\n",
    "\n",
    "# `lowercase=False`로 할 시 `strip_accent=False`로 해야함\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    vocab=vocab_path,\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=True,\n",
    "    strip_accents=True, # Must be False if cased model\n",
    "    lowercase=True,\n",
    "    wordpieces_prefix=\"##\"\n",
    ")\n",
    "print(\"WP 토크나이저 생성중\")\n",
    "tokenizer.train(\n",
    "    files=[train_file_path],\n",
    "    limit_alphabet=args.limit_alphabet,\n",
    "    vocab_size=args.vocab_size\n",
    ")\n",
    "print(\"vocab 파일 이동 %s -> %s\"%(vocab_path, move_vocab_path))\n",
    "# 원본 vocab.txt 파일 옮기기\n",
    "shutil.move(vocab_path, move_vocab_path)\n",
    "\n",
    "print(\"new vocab 파일 저장 %s\"%vocab_path)\n",
    "vocab_list = [i[0] for i in sorted(tokenizer.get_vocab().items(), key=lambda x: x[1])]\n",
    "with open(vocab_path, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    for vocab in vocab_list:\n",
    "        f.write(vocab+\"\\n\")\n",
    "\n",
    "    for i in range(args.un_used_num):\n",
    "        f.write(\"[unused%s]\\n\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/cujabes/koelectra-small-v3-discriminator/commit/60d2d671aebc0220fca2e7725edbf396ea7f163e', commit_message='Upload vocab.txt with huggingface_hub', commit_description='', oid='60d2d671aebc0220fca2e7725edbf396ea7f163e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### vocab 파일 업데이트\n",
    "\n",
    "REPO_NAME = \"cujabes/koelectra-small-v3-discriminator\"\n",
    "\n",
    "# 기존 vocab file 삭제\n",
    "delete_file(\n",
    "    \"vocab.txt\",\n",
    "    repo_id=REPO_NAME,\n",
    ")\n",
    "\n",
    "# 새로운 vocab 파일 업로드\n",
    "upload_file(\n",
    "    path_or_fileobj=vocab_path,\n",
    "    path_in_repo=\"vocab.txt\",\n",
    "    repo_id=REPO_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/cujabes/koelectra-small-v3-discriminator/commit/68e631438ce3af95a0108f9aeefbaeb368052229', commit_message='Upload config.json with huggingface_hub', commit_description='', oid='68e631438ce3af95a0108f9aeefbaeb368052229', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 vocab file 삭제\n",
    "delete_file(\n",
    "    \"config.json\",\n",
    "    repo_id=REPO_NAME,\n",
    ")\n",
    "# 새로운 vocab 파일 업로드\n",
    "upload_file(\n",
    "    path_or_fileobj=\"/root/dothis-ai/models/KoELECTRA/repo/config.json\",\n",
    "    path_in_repo=\"config.json\",\n",
    "    repo_id=REPO_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cujabes/koelectra-small-v3-discriminator does not appear to have a file named config.json. Checkout 'https://huggingface.co/cujabes/koelectra-small-v3-discriminator/main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mget_labels()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 모델 설정 로드\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mElectraConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks_num_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mid2label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlabel2id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU/lib/python3.8/site-packages/transformers/configuration_utils.py:605\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m revision\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_set_token_in_kwargs(kwargs, token)\n\u001b[0;32m--> 605\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m    607\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU/lib/python3.8/site-packages/transformers/configuration_utils.py:634\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    636\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU/lib/python3.8/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU/lib/python3.8/site-packages/transformers/utils/hub.py:356\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         )\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: cujabes/koelectra-small-v3-discriminator does not appear to have a file named config.json. Checkout 'https://huggingface.co/cujabes/koelectra-small-v3-discriminator/main' for available files."
     ]
    }
   ],
   "source": [
    "from transformers import ElectraConfig, ElectraForTokenClassification\n",
    "cache_dir = \"../../../../models/huggingface\"\n",
    "model_name = \"cujabes/koelectra-small-v3-discriminator\"\n",
    "processor = processors[args.task](args)\n",
    "labels = processor.get_labels()\n",
    "# 모델 설정 로드\n",
    "config = ElectraConfig.from_pretrained(model_name, \n",
    "                num_labels=tasks_num_labels[args.task],\n",
    "                id2label={str(i): label for i, label in enumerate(labels)},\n",
    "                label2id={label: i for i, label in enumerate(labels)},cache_dir=cache_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cujabes/koelectra-small-v3-discriminator does not appear to have a file named config.json. Checkout 'https://huggingface.co/cujabes/koelectra-small-v3-discriminator/main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m processor \u001b[38;5;241m=\u001b[39m processors[args\u001b[38;5;241m.\u001b[39mtask](args)\n\u001b[1;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mget_labels()\n\u001b[0;32m----> 4\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mCONFIG_CLASSES\u001b[49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks_num_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid2label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel2id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m TOKENIZER_CLASSES[args\u001b[38;5;241m.\u001b[39mmodel_type]\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     12\u001b[0m     args\u001b[38;5;241m.\u001b[39mmodel_name_or_path,\n\u001b[1;32m     13\u001b[0m     do_lower_case\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdo_lower_case,\n\u001b[1;32m     14\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m MODEL_FOR_TOKEN_CLASSIFICATION[args\u001b[38;5;241m.\u001b[39mmodel_type]\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m.\u001b[39mmodel_name_or_path,\n\u001b[1;32m     18\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     19\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU/lib/python3.8/site-packages/transformers/configuration_utils.py:605\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m revision\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_set_token_in_kwargs(kwargs, token)\n\u001b[0;32m--> 605\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m    607\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU/lib/python3.8/site-packages/transformers/configuration_utils.py:634\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    636\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU/lib/python3.8/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU/lib/python3.8/site-packages/transformers/utils/hub.py:356\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         )\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: cujabes/koelectra-small-v3-discriminator does not appear to have a file named config.json. Checkout 'https://huggingface.co/cujabes/koelectra-small-v3-discriminator/main' for available files."
     ]
    }
   ],
   "source": [
    "cache_dir = \"../../../../models/huggingface\"\n",
    "processor = processors[args.task](args)\n",
    "labels = processor.get_labels()\n",
    "config = CONFIG_CLASSES[args.model_type].from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    num_labels=tasks_num_labels[args.task],\n",
    "    id2label={str(i): label for i, label in enumerate(labels)},\n",
    "    label2id={label: i for i, label in enumerate(labels)},\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "tokenizer = TOKENIZER_CLASSES[args.model_type].from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    do_lower_case=args.do_lower_case,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "model = MODEL_FOR_TOKEN_CLASSIFICATION[args.model_type].from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU or CPU\n",
    "args.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "model.to(args.device)\n",
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/14/2024 04:55:38 - INFO - processor.ner -   Loading features from cached file ../../../../data/KoELECTRA/cached_naver-ner_koelectra-small-v3-discriminator_128_train\n",
      "02/14/2024 04:55:42 - INFO - processor.ner -   Loading features from cached file ../../../../data/KoELECTRA/cached_naver-ner_koelectra-small-v3-discriminator_128_test\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train\") if args.train_file else None\n",
    "dev_dataset = load_and_cache_examples(args, tokenizer, mode=\"dev\") if args.dev_file else None\n",
    "test_dataset = load_and_cache_examples(args, tokenizer, mode=\"test\") if args.test_file else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev_dataset == None:\n",
    "    args.evaluate_test_during_training = True  # If there is no dev dataset, only use testset\n",
    "\n",
    "if args.do_train:\n",
    "    global_step, tr_loss = train_v2(args, model, train_dataset, dev_dataset, test_dataset)\n",
    "    logger.info(\" global_step = {}, average loss = {}\".format(global_step, tr_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/14/2024 04:55:44 - INFO - __main__ -   Evaluate the following checkpoints: ['../../../../models/KoELECTRA/koelectra-small-v3-naver-ner-ckpt/checkpoint-best']\n",
      "02/14/2024 04:55:44 - INFO - run_ner -   ***** Running evaluation on test dataset (best step) *****\n",
      "02/14/2024 04:55:44 - INFO - run_ner -     Num examples = 9000\n",
      "02/14/2024 04:55:44 - INFO - run_ner -     Eval Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../../../models/KoELECTRA/koelectra-small-v3-naver-ner-ckpt/checkpoint-best']\n",
      " |████████████████████████████████████████| 100.00% [71/71 00:02<00:00]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/14/2024 04:55:47 - INFO - run_ner -   ***** Eval results on test dataset *****\n",
      "02/14/2024 04:55:47 - INFO - run_ner -     f1 = 0.8594204130194611\n",
      "02/14/2024 04:55:47 - INFO - run_ner -     loss = 0.2844202115502156\n",
      "02/14/2024 04:55:47 - INFO - run_ner -     precision = 0.8544969074255585\n",
      "02/14/2024 04:55:47 - INFO - run_ner -     recall = 0.8644009846827133\n",
      "02/14/2024 04:55:48 - INFO - run_ner -   \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AFW       0.58      0.61      0.60       394\n",
      "         ANM       0.77      0.78      0.78       701\n",
      "         CVL       0.84      0.84      0.84      5758\n",
      "         DAT       0.92      0.93      0.92      2521\n",
      "         EVT       0.77      0.78      0.78      1094\n",
      "         FLD       0.60      0.68      0.63       228\n",
      "         LOC       0.85      0.86      0.85      2126\n",
      "         MAT       0.17      0.17      0.17        12\n",
      "         NUM       0.92      0.93      0.92      5590\n",
      "         ORG       0.88      0.87      0.87      4086\n",
      "         PER       0.88      0.89      0.88      4426\n",
      "         PLT       0.27      0.18      0.21        34\n",
      "         TIM       0.86      0.93      0.90       314\n",
      "         TRM       0.73      0.74      0.74      1964\n",
      "\n",
      "   micro avg       0.85      0.86      0.86     29248\n",
      "   macro avg       0.72      0.73      0.72     29248\n",
      "weighted avg       0.85      0.86      0.86     29248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "if args.do_eval:\n",
    "    checkpoints = list(os.path.dirname(c) for c in\n",
    "                        # sorted(glob.glob(args.output_dir + \"/**/\" + \"pytorch_model.bin\", recursive=True), key=lambda path_with_step: list(map(int, re.findall(r\"\\d+\", path_with_step)))[-1]))\n",
    "                        sorted(glob.glob(args.output_dir + \"/**/\" + \"training_args.bin\", recursive=True), key=lambda path_with_step: list(map(int, re.findall(r\"\\d+\", path_with_step)))[-1]))\n",
    "\n",
    "    print(checkpoints)\n",
    "    if not args.eval_all_checkpoints:\n",
    "        checkpoints = checkpoints[-1:]\n",
    "    else:\n",
    "        logging.getLogger(\"transformers.configuration_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "        logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "    for checkpoint in checkpoints:\n",
    "        global_step = checkpoint.split(\"-\")[-1]\n",
    "        model = MODEL_FOR_TOKEN_CLASSIFICATION[args.model_type].from_pretrained(checkpoint)\n",
    "        model.to(args.device)\n",
    "        result = evaluate(args, model, test_dataset, mode=\"test\", global_step=global_step)\n",
    "        result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
    "        results.update(result)\n",
    "\n",
    "    output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as f_w:\n",
    "        if len(checkpoints) > 1:\n",
    "            for key in sorted(results.keys(), key=lambda key_with_step: (\n",
    "                    \"\".join(re.findall(r'[^_]+_', key_with_step)),\n",
    "                    int(re.findall(r\"_\\d+\", key_with_step)[-1][1:])\n",
    "            )):\n",
    "                f_w.write(\"{} = {}\\n\".format(key, str(results[key])))\n",
    "        else:\n",
    "            for key in sorted(results.keys()):\n",
    "                f_w.write(\"{} = {}\\n\".format(key, str(results[key])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델파일들을 repo 경로에 복사\n",
    "\n",
    "# 원본 파일 경로\n",
    "source_path = \"../../../../models/KoELECTRA/koelectra-small-v3-naver-ner-ckpt/checkpoint-best/*\"\n",
    "# 대상 파일 경로 (복사될 위치와 파일 이름)\n",
    "target_path = \"../../../../models/KoELECTRA/repo/\"\n",
    "\n",
    "# print(glob(source_path))\n",
    "for source_file in glob(source_path):\n",
    "    filename = os.path.basename(source_file)\n",
    "    target_file = os.path.join(target_path, filename)\n",
    "    print(source_file, target_file)\n",
    "    # 파일 복사\n",
    "    shutil.copyfile(source_file, target_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원격 저장소에 업로드\n",
    "commit_message = 'Initial commit'\n",
    "repo.git_add()\n",
    "repo.git_commit(commit_message)\n",
    "repo.git_push()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
